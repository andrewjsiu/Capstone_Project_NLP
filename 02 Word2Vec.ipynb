{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Using Word2Vec to Predict Review Usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_directory = os.path.join('C:/Users/andre/Documents/yelp_dataset_challenge_round9')\n",
    "intermediate_directory = os.path.join(data_directory, 'intermediate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(intermediate_directory, 'useful.csv'))\n",
    "luseful = np.log(df['useful'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,382 terms in the word2vec vocabulary.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_filepath = os.path.join(intermediate_directory, 'word2vec_model_all')\n",
    "word2vec = Word2Vec.load(word2vec_filepath)\n",
    "\n",
    "print(u'{:,} terms in the word2vec vocabulary.'.format(len(word2vec.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a list of terms, index, and term counts from the word2vec model\n",
    "ordered_vocab = [(term, vocab.index, vocab.count) for term, vocab in word2vec.wv.vocab.items()]\n",
    "ordered_vocab = sorted(ordered_vocab, key=lambda ordered_vocab:ordered_vocab[2], reverse=True)\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creat a dictionary mapping each word to a 100-dimensional vector\n",
    "word_vectors = dict(list(zip(word2vec.wv.index2word, word2vec.wv.syn0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error,\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_reviews_filepath = os.path.join(intermediate_directory, 'trigram_transformed_reviews_all.txt')\n",
    "\n",
    "X = []\n",
    "with codecs.open(trigram_reviews_filepath, encoding='utf-8') as f:\n",
    "    for review in f:\n",
    "        X.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer():\n",
    "    \n",
    "    \"\"\" Given a word to vector mapping, vectorize texts by taking the mean of all the word vectors for each document\"\"\"\n",
    "    \n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(list(word2vec.values())[0])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in review if w in self.word2vec] \n",
    "                   or [np.zeros(self.dim)], axis=0) \n",
    "                   for review in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfidfMeanVectorizer():\n",
    "    \n",
    "    \"\"\" Vectorize texts by taking the weighted average word vectors by their TF-IDF\"\"\"\n",
    "    \n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(list(word2vec.values())[0])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x:x)\n",
    "        tfidf.fit(X)\n",
    "        # Let an unseem word be as infrequent as the most infreqeunt word\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                                 for w in review if w in self.word2vec] or \n",
    "                                [np.zeros(self.dim)], axis=0) \n",
    "                         for review in X])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_rmse(model, X, y, cv=5, scoring='neg_mean_squared_error'):\n",
    "    \n",
    "    \"\"\" Compute an overall RMSE across all folds of cross validation\"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean(np.multiply(cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error'), -1)))\n",
    "    \n",
    "def RMSE(y_true, y_pred):\n",
    "    \n",
    "    \"\"\" Root Mean Squared Error\"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def RMSLE(y_true, y_pred):\n",
    "    \n",
    "    \"\"\" Root Mean Squared Logarithmic Error\"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean(((np.log(y_true + 1) - np.log(y_pred + 1))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor().fit(MeanEmbeddingVectorizer(word_vectors).fit(X, luseful).transform(X), luseful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the predicted usefulness of each word\n",
    "words = np.array(list(word_vectors.keys()))\n",
    "predicted = xgb.predict(list(word_vectors.values()))\n",
    "indices = np.argsort(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Words      Predicted Useful Votes\n",
      "-------------------  ------------------------\n",
      "ma                                   0.852082\n",
      "20                                   0.839871\n",
      "$                                    0.83384\n",
      "then                                 0.805797\n",
      "lunch                                0.782742\n",
      "ultrasound_tech                      0.723978\n",
      "$_50                                 0.712948\n",
      "tech                                 0.710443\n",
      "o'clock                              0.683837\n",
      "early                                0.678982\n"
     ]
    }
   ],
   "source": [
    "useful_words = words[indices[-10:]]\n",
    "useful_pred = predicted[indices[-10:]]\n",
    "df = pd.DataFrame({'Most Useful Words': useful_words, 'Predicted Useful Votes': np.exp(useful_pred)-1})\n",
    "print (tabulate(df.sort_values('Predicted Useful Votes', ascending=False), headers=df.columns, showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Useful Words      Predicted Useful Votes\n",
      "--------------------  ------------------------\n",
      "pain_management                      -0.153879\n",
      "record                               -0.128184\n",
      "formal_complaint                     -0.126984\n",
      "insulin                              -0.113906\n",
      "kudo                                 -0.110864\n",
      "plastic_surgery                      -0.108482\n",
      "cosmetic_surgery                     -0.107434\n",
      "inquire_about                        -0.105374\n",
      "correction                           -0.101546\n",
      "endoscopy                            -0.098754\n"
     ]
    }
   ],
   "source": [
    "useless_words = words[indices[:10]]\n",
    "useless_pred = predicted[indices[:10]]\n",
    "df = pd.DataFrame({'Least Useful Words': useless_words, 'Predicted Useful Votes': np.exp(useless_pred)-1})\n",
    "print (tabulate(df, headers=df.columns, showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression and shrinkage methods: Ridge and lasso\n",
    "\n",
    "lr_w2v = Pipeline([(\"w2v_vectorizer\", MeanEmbeddingVectorizer(word_vectors)), \n",
    "                   (\"lr\", LinearRegression())])\n",
    "lr_w2v_tfidf = Pipeline([(\"tfidf_w2v_vectorizer\", TfidfMeanVectorizer(word_vectors)),\n",
    "                        (\"lr\", LinearRegression())])\n",
    "ridge_w2v = Pipeline([(\"w2v_vectorizer\", MeanEmbeddingVectorizer(word_vectors)),\n",
    "                    (\"ridge\", Ridge(alpha=1))])\n",
    "ridge_w2v_tfidf = Pipeline([(\"tfidf_w2v_vectorizer\", TfidfMeanVectorizer(word_vectors)),\n",
    "                    (\"ridge\", Ridge(alpha=1))])                            \n",
    "rfr_w2v = Pipeline([(\"w2v_vectorizer\", MeanEmbeddingVectorizer(word_vectors)),\n",
    "                    (\"rfr\", RandomForestRegressor(n_estimators=100))])                            \n",
    "xgb_w2v = Pipeline([(\"w2v_vectorizer\", MeanEmbeddingVectorizer(word_vectors)),\n",
    "                    (\"xgb\", XGBRegressor(n_estimators=100))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model              RMSE_5cv\n",
      "---------------  ----------\n",
      "xgb_w2v              0.6037\n",
      "rfr_w2v              0.6130\n",
      "ridge_w2v_tfidf      0.6175\n",
      "ridge_w2v            0.6176\n",
      "lr_w2v_tfidf       175.3874\n",
      "lr_w2v             324.2977\n"
     ]
    }
   ],
   "source": [
    "w2v_models = [(\"lr_w2v\", lr_w2v), (\"lr_w2v_tfidf\", lr_w2v_tfidf),\n",
    "              (\"ridge_w2v\", ridge_w2v), (\"ridge_w2v_tfidf\", ridge_w2v_tfidf),\n",
    "              (\"rfr_w2v\", rfr_w2v), (\"xgb_w2v\", xgb_w2v)]\n",
    "\n",
    "w2v_rmse = sorted([(name, cv_rmse(model, X, luseful, cv=5)) \n",
    "                     for name, model in w2v_models], key=lambda x:x[1])\n",
    "\n",
    "print (tabulate(w2v_rmse, floatfmt=\".4f\", headers=(\"model\", \"RMSE_5cv\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
